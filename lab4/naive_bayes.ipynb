{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of examples are:  768\n",
      "Out of these, training examples are:  614\n",
      "Test examples are:  154\n",
      "Accuracy of your model is:  77.92207792207793\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import csv\n",
    " \n",
    " \n",
    "# the categorical class names are changed to numberic data\n",
    "# eg: yes and no encoded to 1 and 0\n",
    "def encode_class(mydata):\n",
    "    classes = []\n",
    "    for i in range(len(mydata)):\n",
    "        if mydata[i][-1] not in classes:\n",
    "            classes.append(mydata[i][-1])\n",
    "    for i in range(len(classes)):\n",
    "        for j in range(len(mydata)):\n",
    "            if mydata[j][-1] == classes[i]:\n",
    "                mydata[j][-1] = i\n",
    "    return mydata           \n",
    "             \n",
    " \n",
    "# Splitting the data\n",
    "def splitting(mydata, ratio):\n",
    "    train_num = int(len(mydata) * ratio)\n",
    "    train = []\n",
    "    # initially testset will have all the dataset\n",
    "    test = list(mydata)\n",
    "    while len(train) < train_num:\n",
    "        # index generated randomly from range 0\n",
    "        # to length of testset\n",
    "        index = random.randrange(len(test))\n",
    "        # from testset, pop data rows and put it in train\n",
    "        train.append(test.pop(index))\n",
    "    return train, test\n",
    " \n",
    " \n",
    "# Group the data rows under each class yes or\n",
    "# no in dictionary eg: dict[yes] and dict[no]\n",
    "def groupUnderClass(mydata):\n",
    "      dict = {}\n",
    "      for i in range(len(mydata)):\n",
    "          if (mydata[i][-1] not in dict):\n",
    "              dict[mydata[i][-1]] = []\n",
    "          dict[mydata[i][-1]].append(mydata[i])\n",
    "      return dict\n",
    " \n",
    " \n",
    "# Calculating Mean\n",
    "def mean(numbers):\n",
    "    return sum(numbers) / float(len(numbers))\n",
    " \n",
    "# Calculating Standard Deviation\n",
    "def std_dev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([pow(x - avg, 2) for x in numbers]) / float(len(numbers) - 1)\n",
    "    return math.sqrt(variance)\n",
    " \n",
    "def MeanAndStdDev(mydata):\n",
    "    info = [(mean(attribute), std_dev(attribute)) for attribute in zip(*mydata)]\n",
    "    # eg: list = [ [a, b, c], [m, n, o], [x, y, z]]\n",
    "    # here mean of 1st attribute =(a + m+x), mean of 2nd attribute = (b + n+y)/3\n",
    "    # delete summaries of last class\n",
    "    del info[-1]\n",
    "    return info\n",
    " \n",
    "# find Mean and Standard Deviation under each class\n",
    "def MeanAndStdDevForClass(mydata):\n",
    "    info = {}\n",
    "    dict = groupUnderClass(mydata)\n",
    "    for classValue, instances in dict.items():\n",
    "        info[classValue] = MeanAndStdDev(instances)\n",
    "    return info\n",
    " \n",
    " \n",
    "# Calculate Gaussian Probability Density Function\n",
    "def calculateGaussianProbability(x, mean, stdev):\n",
    "    expo = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2))))\n",
    "    return (1 / (math.sqrt(2 * math.pi) * stdev)) * expo\n",
    " \n",
    " \n",
    "# Calculate Class Probabilities\n",
    "def calculateClassProbabilities(info, test):\n",
    "    probabilities = {}\n",
    "    for classValue, classSummaries in info.items():\n",
    "        probabilities[classValue] = 1\n",
    "        for i in range(len(classSummaries)):\n",
    "            mean, std_dev = classSummaries[i]\n",
    "            x = test[i]\n",
    "            probabilities[classValue] *= calculateGaussianProbability(x, mean, std_dev)\n",
    "    return probabilities\n",
    " \n",
    " \n",
    "# Make prediction - highest probability is the prediction\n",
    "def predict(info, test):\n",
    "    probabilities = calculateClassProbabilities(info, test)\n",
    "    bestLabel, bestProb = None, -1\n",
    "    for classValue, probability in probabilities.items():\n",
    "        if bestLabel is None or probability > bestProb:\n",
    "            bestProb = probability\n",
    "            bestLabel = classValue\n",
    "    return bestLabel\n",
    " \n",
    " \n",
    "# returns predictions for a set of examples\n",
    "def getPredictions(info, test):\n",
    "    predictions = []\n",
    "    for i in range(len(test)):\n",
    "        result = predict(info, test[i])\n",
    "        predictions.append(result)\n",
    "    return predictions\n",
    " \n",
    "# Accuracy score\n",
    "def accuracy_rate(test, predictions):\n",
    "    correct = 0\n",
    "    for i in range(len(test)):\n",
    "        if test[i][-1] == predictions[i]:\n",
    "            correct += 1\n",
    "    return (correct / float(len(test))) * 100.0\n",
    " \n",
    " \n",
    "# driver code\n",
    " \n",
    "# add the data path in your system\n",
    "filename = r'./diabetes.csv'\n",
    " \n",
    " \n",
    "# load the file and store it in mydata list\n",
    "mydata = csv.reader(open(filename, \"rt\"))\n",
    "mydata = list(mydata)\n",
    "mydata = encode_class(mydata)\n",
    "for i in range(len(mydata)):\n",
    "    mydata[i] = [float(x) for x in mydata[i]]\n",
    " \n",
    "     \n",
    "# split ratio = 0.7\n",
    "# 70% of data is training data and 30% is test data used for testing\n",
    "ratio = 0.8\n",
    "train_data, test_data = splitting(mydata, ratio)\n",
    "print('Total number of examples are: ', len(mydata))\n",
    "print('Out of these, training examples are: ', len(train_data))\n",
    "print(\"Test examples are: \", len(test_data))\n",
    " \n",
    "# prepare model\n",
    "info = MeanAndStdDevForClass(train_data)\n",
    " \n",
    "# test model\n",
    "predictions = getPredictions(info, test_data)\n",
    "accuracy = accuracy_rate(test_data, predictions)\n",
    "print(\"Accuracy of your model is: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\n",
       "0   1            5.1           3.5            1.4           0.2\n",
       "1   2            4.9           3.0            1.4           0.2\n",
       "2   3            4.7           3.2            1.3           0.2\n",
       "3   4            4.6           3.1            1.5           0.2\n",
       "4   5            5.0           3.6            1.4           0.2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.read_csv(r'./Iris.csv')\n",
    "y=dataset[['Species']]\n",
    "X=dataset.drop(['Species'],axis=1)\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,y,test_size= 0.4,random_state=42) #random splitting data\n",
    "scaler=StandardScaler()\n",
    "scale=scaler.fit(X_train)\n",
    "X_train=scale.transform(X_train)\n",
    "X_test=scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        23\n",
      "Iris-versicolor       1.00      1.00      1.00        19\n",
      " Iris-virginica       1.00      1.00      1.00        18\n",
      "\n",
      "       accuracy                           1.00        60\n",
      "      macro avg       1.00      1.00      1.00        60\n",
      "   weighted avg       1.00      1.00      1.00        60\n",
      "\n",
      "[[23  0  0]\n",
      " [ 0 19  0]\n",
      " [ 0  0 18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\prana\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\validation.py:1111: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "model=GaussianNB()\n",
    "model.fit(X_train,Y_train)\n",
    "predicted=model.predict(X_test)\n",
    "print(metrics.classification_report(Y_test,predicted))\n",
    "print(metrics.confusion_matrix(Y_test,predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "35c754d8008c5f8560e4adf341ebf96f62d30db323e3ac43f60a1cb4dab6d757"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
